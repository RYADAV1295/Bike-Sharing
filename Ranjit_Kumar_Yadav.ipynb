{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataSet = pd.read_csv(\"./data/day.csv\")\n",
    "bike_dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Description\n",
    "bike_dataSet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataSet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataSet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data Analysis:***\n",
    "- Total Records are 730 x 16\n",
    "- All the columns except dteday i.e. date object type are either integer or float\n",
    "- There are fields that are categorical in nature, but their values are integer/float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "\n",
    "round(100*(bike_dataSet.isnull().sum()/len(bike_dataSet)), 2).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataSet_dup = bike_dataSet.copy()\n",
    "bike_dataSet_dup.drop_duplicates(subset=None, inplace=True)\n",
    "bike_dataSet_dup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataSet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data Analysis:***\n",
    "- There is no missing value in the data set\n",
    "- There is no duplicate values as the shape is equal for both duplicate data set and actual data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataSet.drop(columns=['instant','dteday','casual','registered'],axis=1,inplace=True)\n",
    "bike_dataSet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data Analysis and Actions:***\n",
    "- \"instant\" column is the serial no, so we can remove this\n",
    "- \"dteday\" column is the dat type column whichis not required as we have year, month columns present\n",
    "- as our target is to achieve the total number of bikes used, we can remove the \"casual\" and \"registered\" columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataSet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing season int value to string\n",
    "bike_dataSet['season']=bike_dataSet['season'].map({1:'spring', 2:'summer', 3:'fall', 4:'winter'})\n",
    "# bike_dataSet['weekday']=bike_dataSet['weekday'].map({0:'sunday',1:'monday', 2:'teusday', 3:'wednesday', 4:'thursday',5:'friday',6:'saturday'})\n",
    "# bike_dataSet['mnth']=bike_dataSet['mnth'].map({1:'jan', 2:'feb', 3:'mar', 4:'apr',5:'may',6:'jun',7:'jul',8:'aug',9:'sep',10:'oct',11:'nov',12:'dec'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataSet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 fields for whih we need to create dummy variables as they are the categorical variables\n",
    "- \"mnth\"\n",
    "- \"weekday\"\n",
    "- \"season\"\n",
    "- \"weathersit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the categorical columns beofre creating the dummy variables\n",
    "bike_dataSet['season']=bike_dataSet['season'].astype('category')\n",
    "bike_dataSet['weathersit']=bike_dataSet['weathersit'].astype('category')\n",
    "bike_dataSet['mnth']=bike_dataSet['mnth'].astype('category')\n",
    "bike_dataSet['weekday']=bike_dataSet['weekday'].astype('category')\n",
    "bike_dataSet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables and droping first column\n",
    "# This function will create dummy variable and drop the respective columns and drop first columns\n",
    "bike_clean_dataSet = pd.get_dummies(bike_dataSet,drop_first=True)\n",
    "bike_clean_dataSet.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization With Pair Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data visualizing for non categorical data\n",
    "bike_num=bike_clean_dataSet[[ 'cnt','temp', 'atemp', 'hum', 'windspeed']]\n",
    "\n",
    "sns.pairplot(bike_num, diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis\n",
    "- There is a linear relation inbetween cnt, atemp and temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization With Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "plt.subplot(2,3,1)\n",
    "sns.boxplot(x = 'season', y = 'cnt', data = bike_dataSet)\n",
    "plt.subplot(2,3,2)\n",
    "sns.boxplot(x = 'mnth', y = 'cnt', data = bike_dataSet)\n",
    "plt.subplot(2,3,3)\n",
    "sns.boxplot(x = 'weathersit', y = 'cnt', data = bike_dataSet)\n",
    "plt.subplot(2,3,4)\n",
    "sns.boxplot(x = 'holiday', y = 'cnt', data = bike_dataSet)\n",
    "plt.subplot(2,3,5)\n",
    "sns.boxplot(x = 'weekday', y = 'cnt', data = bike_dataSet)\n",
    "plt.subplot(2,3,6)\n",
    "sns.boxplot(x = 'workingday', y = 'cnt', data = bike_dataSet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Categorical data\n",
    "\n",
    "- season can be a good predictor for our model as the season 3 has the median almost at par 5000, and season 2 and 4 also behind that with median of 4000+\n",
    "- mnth also can be a good predictor as it also shows that the bike booking go up in the month of 9th followed by 6th, 8th and 10th.\n",
    "- weathersit is a good predictor too as it clearly shows that the weathersit1 has the median of 5000+\n",
    "- Rest of them we will se how the model predicts as there is not much diference in their median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splliting Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We specify this so that the train and test data set always have the same rows, respectively\n",
    "np.random.seed(0)\n",
    "bike_train_set, bike_test_set = train_test_split(bike_clean_dataSet, train_size = 0.7, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bike_train_set.shape)\n",
    "print(bike_test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling the Features\n",
    "- we need to rescale some data so that they have a comparabel scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# Apply scaler() to all the columns except 'dummy' variables and 1/0 variable\n",
    "num_vars = ['temp', 'atemp', 'hum', 'windspeed', 'cnt']\n",
    "# Scaling the Train Set\n",
    "bike_train_set[num_vars] = scaler.fit_transform(bike_train_set[num_vars])\n",
    "bike_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_train_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is bieng rescaled, every data have the max as 1 and min as 0. this will help tp get better correleation among the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting up a correlation matrix\n",
    "- Visualizing correlation coefficients to see what variables are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30, 25))\n",
    "sns.heatmap(bike_train_set.corr(), annot = True, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see temp and atemp are highly corelated with cnt, lets see a scatter plot to visualize the trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting up a Scatter Plot\n",
    "- Visualizing Linearity in tem and atemp variable w.r.t cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,6])\n",
    "plt.scatter(bike_train_set.temp, bike_train_set.cnt)\n",
    "plt.scatter(bike_train_set.atemp, bike_train_set.cnt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see atemp and temp has a clear linear line rising up with the cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection & Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Approach - Automated RFE + Manual removing feature using VIF and P-Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing training set into X and Y sets for the model building\n",
    "y_bike_train_cnt = bike_train_set.pop('cnt')\n",
    "X_bike_train_set = bike_train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection\n",
    "- We will be using the LinearRegression function from SciKit Learn for its compatibility with RFE (which is a utility from sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the lr Object\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_bike_train_set, y_bike_train_cnt)\n",
    "\n",
    "# Taking 10 columns initially as feature to be selected\n",
    "rfe = RFE(estimator=lr,n_features_to_select=15)\n",
    "rfe = rfe.fit(X_bike_train_set, y_bike_train_cnt)\n",
    "list(zip(X_bike_train_set.columns,rfe.support_,rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE supported column\n",
    "rfe_sup_col = X_bike_train_set.columns[rfe.support_]\n",
    "rfe_sup_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  RFE non supporting columns\n",
    "X_bike_train_set.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame only selecting the RFE supported variables\n",
    "X_bike_train_set_rfe = X_bike_train_set[rfe_sup_col]\n",
    "X_bike_train_set_rfe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Building\n",
    "- Building model using statsmodel, for the detailed statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the constant variable\n",
    "X_bike_train_lrm = sm.add_constant(X_bike_train_set_rfe)\n",
    "X_bike_train_lrm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the LR Model\n",
    "lrm = sm.OLS(y_bike_train_cnt,X_bike_train_lrm.astype(float)).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the summary of our LR Model\n",
    "print(lrm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"R-Squared: \"}{round(lrm.rsquared * 100,1)}{\"%\"}')\n",
    "print(f'{\"Adj.R-Squared: \"}{round(lrm.rsquared_adj * 100,1)}{\"%\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove added const variable before VIF Calculation\n",
    "X_bike_train_vif = X_bike_train_lrm.drop(['const'], axis=1)\n",
    "# Check for the VIF values of the feature variables. \n",
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_bike_train_vif.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_bike_train_vif.astype(float).values, i) for i in range(X_bike_train_vif.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- According to the VIF table and above summary, 'hum',''temp' and 'workingday' has VIF value > 5 i.e. high multicollinearity with 'p value' at '0.0' which is under 0.05.\n",
    "- We need to remove the high VIF features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing High VIF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bike_train_set_rfe=X_bike_train_set_rfe.drop(['hum'],axis=1)\n",
    "X_bike_train_set_rfe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Re-Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant again\n",
    "X_bike_train_lrm = sm.add_constant(X_bike_train_set_rfe)\n",
    "X_bike_train_lrm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the LR Model again with new set of features\n",
    "lrm = sm.OLS(y_bike_train_cnt,X_bike_train_lrm.astype(float)).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the summary of our latest LR Model\n",
    "print(lrm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"R-Squared: \"}{round(lrm.rsquared * 100,1)}{\"%\"}')\n",
    "print(f'{\"Adj.R-Squared: \"}{round(lrm.rsquared_adj * 100,1)}{\"%\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove added const variable before VIF Calculation\n",
    "X_bike_train_vif = X_bike_train_lrm.drop(['const'], axis=1)\n",
    "# Check for the VIF values of the feature variables. \n",
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_bike_train_vif.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_bike_train_vif.astype(float).values, i) for i in range(X_bike_train_vif.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- According to the VIF table and above summary, 'temp' and 'workingday' has VIF value > 5 i.e. high multicollinearity with 'p value' at '0.0' which is under 0.05.\n",
    "- But 'temp' has high significance with ' target variable 'cnt;.\n",
    "- So, We need to remove the high P-Value features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing High P-Value Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bike_train_set_rfe=X_bike_train_set_rfe.drop(['mnth_8'],axis=1)\n",
    "X_bike_train_set_rfe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Re-Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant again\n",
    "X_bike_train_lrm = sm.add_constant(X_bike_train_set_rfe)\n",
    "X_bike_train_lrm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the LR Model\n",
    "lrm = sm.OLS(y_bike_train_cnt,X_bike_train_lrm.astype(float)).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the summary of our latest LR Model\n",
    "print(lrm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"R-Squared: \"}{round(lrm.rsquared * 100,1)}{\"%\"}')\n",
    "print(f'{\"Adj.R-Squared: \"}{round(lrm.rsquared_adj * 100,1)}{\"%\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove added const variable before VIF Calculation\n",
    "X_bike_train_vif = X_bike_train_lrm.drop(['const'], axis=1)\n",
    "# Check for the VIF values of the feature variables. \n",
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_bike_train_vif.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_bike_train_vif.astype(float).values, i) for i in range(X_bike_train_vif.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- According to the VIF table and above summary, all feature has VIF < 5.\n",
    "- Therefore removing High P-Value fature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing High P-Value Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bike_train_set_rfe=X_bike_train_set_rfe.drop(['mnth_6'],axis=1)\n",
    "X_bike_train_set_rfe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Re-Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant again\n",
    "X_bike_train_lrm = sm.add_constant(X_bike_train_set_rfe)\n",
    "X_bike_train_lrm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the LR Model\n",
    "lrm = sm.OLS(y_bike_train_cnt,X_bike_train_lrm.astype(float)).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the summary of our latest LR Model\n",
    "print(lrm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"R-Squared: \"}{round(lrm.rsquared * 100,1)}{\"%\"}')\n",
    "print(f'{\"Adj.R-Squared: \"}{round(lrm.rsquared_adj * 100,1)}{\"%\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove added const variable before VIF Calculation\n",
    "X_bike_train_vif = X_bike_train_lrm.drop(['const'], axis=1)\n",
    "# Check for the VIF values of the feature variables. \n",
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_bike_train_vif.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_bike_train_vif.astype(float).values, i) for i in range(X_bike_train_vif.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- According to the VIF table and above summary, all feature has VIF < 5.\n",
    "- Therefore removing high P-Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing High P-Value Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bike_train_set_rfe=X_bike_train_set_rfe.drop(['mnth_4'],axis=1)\n",
    "X_bike_train_set_rfe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Re-Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant again\n",
    "X_bike_train_lrm = sm.add_constant(X_bike_train_set_rfe)\n",
    "X_bike_train_lrm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the LR Model\n",
    "lrm = sm.OLS(y_bike_train_cnt,X_bike_train_lrm.astype(float)).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the summary of our latest LR Model\n",
    "print(lrm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"R-Squared: \"}{round(lrm.rsquared * 100,1)}{\"%\"}')\n",
    "print(f'{\"Adj.R-Squared: \"}{round(lrm.rsquared_adj * 100,1)}{\"%\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove added const variable before VIF Calculation\n",
    "X_bike_train_vif = X_bike_train_lrm.drop(['const'], axis=1)\n",
    "# Check for the VIF values of the feature variables. \n",
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_bike_train_vif.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_bike_train_vif.astype(float).values, i) for i in range(X_bike_train_vif.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- According to the VIF table and above summary, all feature has VIF < 5.\n",
    "- Therefore considering this the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing High P-Value Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bike_train_set_rfe=X_bike_train_set_rfe.drop(['mnth_5'],axis=1)\n",
    "X_bike_train_set_rfe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Re-Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant again\n",
    "X_bike_train_lrm = sm.add_constant(X_bike_train_set_rfe)\n",
    "X_bike_train_lrm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the LR Model\n",
    "lrm = sm.OLS(y_bike_train_cnt,X_bike_train_lrm.astype(float)).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the summary of our latest LR Model\n",
    "print(lrm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"R-Squared: \"}{round(lrm.rsquared * 100,1)}{\"%\"}')\n",
    "print(f'{\"Adj.R-Squared: \"}{round(lrm.rsquared_adj * 100,1)}{\"%\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove added const variable before VIF Calculation\n",
    "X_bike_train_vif = X_bike_train_lrm.drop(['const'], axis=1)\n",
    "# Check for the VIF values of the feature variables. \n",
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_bike_train_vif.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_bike_train_vif.astype(float).values, i) for i in range(X_bike_train_vif.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- According to the VIF table and above summary, all feature has VIF < 5.\n",
    "- Therefore removing high P-Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing High P-Value Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bike_train_set_rfe=X_bike_train_set_rfe.drop(['mnth_3'],axis=1)\n",
    "X_bike_train_set_rfe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Re-Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding constant again\n",
    "X_bike_train_lrm = sm.add_constant(X_bike_train_set_rfe)\n",
    "X_bike_train_lrm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the LR Model\n",
    "lrm = sm.OLS(y_bike_train_cnt,X_bike_train_lrm.astype(float)).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the summary of our latest LR Model\n",
    "print(lrm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"R-Squared: \"}{round(lrm.rsquared * 100,1)}{\"%\"}')\n",
    "print(f'{\"Adj.R-Squared: \"}{round(lrm.rsquared_adj * 100,1)}{\"%\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove added const variable before VIF Calculation\n",
    "X_bike_train_vif = X_bike_train_lrm.drop(['const'], axis=1)\n",
    "# Check for the VIF values of the feature variables. \n",
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_bike_train_vif.columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_bike_train_vif.astype(float).values, i) for i in range(X_bike_train_vif.shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- According to the VIF table and above summary, all feature has VIF < 5.\n",
    "- And all the P-Values are 0\n",
    "- Therefore considering this the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "Hypothesis testing states that:\n",
    "\n",
    "- H0: B1=B2=......=Bn=0\n",
    "- H1: at least one Bi!=0\n",
    "\n",
    "## Final Model Coefficient Values\n",
    "\n",
    "- const             0.2671\n",
    "- yr                0.2354\n",
    "- holiday          -0.0970\n",
    "- temp              0.4078\n",
    "- windspeed        -0.1356\n",
    "- season_spring    -0.1162\n",
    "- season_winter     0.0480\n",
    "- mnth_9            0.0700\n",
    "- weathersit_2     -0.0786\n",
    "- weathersit_3     -0.2885\n",
    "\n",
    "## Insight\n",
    "- It is evident that all our coefficients are not equal to zero, which means We **Reject The NULL Hypothesis**\n",
    "- The F-Statistics value of 233 (which is greater than 1) and the p-value of '~0.0000' states that the overall model is significant\n",
    "\n",
    "## Equation\n",
    "- cnt = 0.2671+(**yr** x 0.2354)+(**holiday** x -0.0970)+(**temp** x 0.4078)+(**windspeed** x -0.1356)+(**season_spring** x -0.1162)+(**season_winter** x 0.0480)+(**mnth_9** x 0.0700)+(**weathersit_2** x 0.0786)+(**weathersit_3** x 0.2885)\n",
    "\n",
    "## Interpretation Of Co-efficients\n",
    "\n",
    "- **const**         : This indicates that in the absence of all other predictor variables, The bike rental can still **increase** by 0.2671 units.\n",
    "- **yr**            : This indicates that a unit increase in this variable, **increases** the bike rental by 0.2354 units.\n",
    "- **holiday**       : This indicates that a unit increase in this variable, **decreases** the bike rental by 0.0970 units.\n",
    "- **temp**          : This indicates that a unit increase in this variable, **increases** the bike rental by 0.4078 units.\n",
    "- **windspeed**     : This indicates that a unit increase in this variable, **decreases** the bike rental by 0.1356 units.\n",
    "- **season_spring** : This indicates that a unit increase in this variable, **decreases** the bike rental by 0.1162 units.\n",
    "- **season_winter** : This indicates that a unit increase in this variable, **increases** the bike rental by 0.0480 units.\n",
    "- **mnth_9**        : This indicates that a unit increase in this variable, **increases** the bike rental by 0.0700 units.\n",
    "- **weathersit_2**  : This indicates that a unit increase in this variable, **decreases** the bike rental by 0.0786 units.\n",
    "- **weathersit_3**  : This indicates that a unit increase in this variable, **decreases** the bike rental by 0.2885 units.\n",
    "\n",
    "### No Multicollinearity between the predictor variables as VIF for all the features are less than 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Analysis Of Trained Data -- Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bike_train_cnt_pred = lrm.predict(X_bike_train_lrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the error terms\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_bike_train_cnt - y_bike_train_cnt_pred), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 14)                  # Plot heading \n",
    "plt.xlabel('Errors', fontsize = 12)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- We can observe tha there is an evenly distribution of errors which is a good sign that the assumption are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_train and y_pred to understand the spread.\n",
    "fig = plt.figure()\n",
    "plt.scatter(y_bike_train_cnt,y_bike_train_cnt_pred)\n",
    "fig.suptitle('Actual Count vs Predicted Count', fontsize=20)              # Plot heading \n",
    "plt.xlabel('Actual Count', fontsize=18)                          # X-label\n",
    "plt.ylabel('Predicted Count', fontsize=16)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the scaling on the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = ['temp', 'atemp', 'hum', 'windspeed', 'cnt']\n",
    "# Scaling the Train Set\n",
    "bike_test_set[num_vars] = scaler.transform(bike_test_set[num_vars])\n",
    "bike_test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing Test Set into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing testing set into X and Y sets for the model building\n",
    "y_bike_test_cnt = bike_test_set.pop('cnt')\n",
    "X_bike_test_set = bike_test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with the Trained Model \"lrm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's use our model to make predictions.\n",
    "X_bike_train_lrm.drop(['const'],axis=1,inplace=True)\n",
    "# Creating X_test_new dataframe by dropping variables from X_test\n",
    "X_bike_test_tm=X_bike_test_set[X_bike_train_lrm.columns]\n",
    "# Adding a constant variable \n",
    "X_bike_test_tm=sm.add_constant(X_bike_test_tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bike_test_cnt_pred = lrm.predict(X_bike_test_tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread.\n",
    "fig = plt.figure()\n",
    "plt.scatter(y_bike_test_cnt,y_bike_test_cnt_pred)\n",
    "fig.suptitle('Actual Count vs Predicted Count', fontsize=20)              # Plot heading \n",
    "plt.xlabel('Actual Count', fontsize=18)                          # X-label\n",
    "plt.ylabel('Predicted Count', fontsize=16)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R^2 Value Of Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"R^2 Score for Training Set : \"}{round(lrm.rsquared * 100,1)}{\"%\"}')\n",
    "print(f'{\"Adjusted R^2 Score for Training Set: \"}{round(lrm.rsquared_adj * 100,1)}{\"%\"}')\n",
    "\n",
    "r2 = r2_score(y_bike_test_cnt, y_bike_test_cnt_pred)\n",
    "print(f'Shape of Test Set: {X_bike_test_tm.shape}')\n",
    "print(f'R^2 Score for the Test Set: {round(r2*100,2)}{\"%\"}')\n",
    "\n",
    "# Number of rows\n",
    "n = X_bike_test_tm.shape[0]\n",
    "\n",
    "# Number of Predictors\n",
    "p = X_bike_test_tm.shape[1]\n",
    "\n",
    "# Adjusted R-squared\n",
    "r2_adj = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print(f'Adjusted R^2 Score for the Test Set: {round(r2_adj*100,2)}{\"%\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Report\n",
    "\n",
    "As per Final Model below are the top 3 predictors which influence the bike bookings:\n",
    "- **Year (yr):** The coefficient for the \"yr\" variable is 0.2354 with a very low p-value (p < 0.001), indicating a highly significant positive effect on bike demand. This suggests that there has been a significant increase in bike rentals over time.\n",
    "- **Temperature (temp):** The coefficient for the \"temp\" variable is 0.4078 with a very low p-value (p < 0.001), indicating a highly significant positive effect on bike demand. This suggests that higher temperatures lead to increased bike rentals, which is intuitive as people are more likely to ride bikes in warmer weather.\n",
    "- **Weather Situation (weathersit):** Both \"weathersit_2\" (partly cloudy) and \"weathersit_3\" (rain/snow/fog) variables have significant coefficients with very low p-values (p < 0.001). However, their coefficients have negative values, indicating a negative effect on bike demand. This suggests that adverse weather conditions (partly cloudy, rain, snow, fog) lead to decreased bike rentals, which is reasonable as people may be less inclined to ride bikes in such weather conditions.\n",
    "\n",
    "Then the next considerable predictors would be as follows:\n",
    "\n",
    "- **Season (season):** Spring season has co-efficient of **-0.1162** which indicates that a unit increase in this variable, **decreases** the bike rental by 0.1162 units. Also Winter season has co-effficient of **0.0480**, which indicates that a unit increase in this variable, **increases** the bike rental by **0.0480** units.\n",
    "- **wiindspeed:** This variable state that a unit increase in this will decrease the bike rental by **0.1356** units.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
